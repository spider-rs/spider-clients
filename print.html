<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>spider-client</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon-de23e50b.svg">
        <link rel="shortcut icon" href="favicon-8114d1fc.png">
        <link rel="stylesheet" href="css/variables-8adf115d.css">
        <link rel="stylesheet" href="css/general-2459343d.css">
        <link rel="stylesheet" href="css/chrome-ae938929.css">
        <link rel="stylesheet" href="css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex-e99e62b0.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc-ae045a77.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">spider-client</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>
                        <a href="https://github.com/spider-rs/spider-clients/tree/main/book" title="Git repository" aria-label="Git repository">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p><code>spider-client</code> is a client library to use with the <a href="https://spider.cloud">Spider Cloud</a> web crawler and scraper.</p>
<ul>
<li>Concurrent</li>
<li>Streaming</li>
<li>Headless Chrome</li>
<li>HTTP Proxies</li>
<li>Cron Jobs</li>
<li>Subscriptions</li>
<li>AI Scraping and Event Driven Actions</li>
<li>Blacklisting and Budgeting Depth</li>
<li>Exponential Backoff</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="simple-example"><a class="header" href="#simple-example">Simple Example</a></h1>
<p>This is a simple example of what you can do with the <code>spider-client</code> library.</p>
<h2 id="installation"><a class="header" href="#installation">Installation</a></h2>
<p>To install the library, you can use <code>pip</code> for Python or <code>npm</code> (make sure to have <a href="https://nodejs.org/en">node</a> installed) for JavaScript.:</p>
<pre><code class="language-bash"># for python
pip install spider-client
</code></pre>
<pre><code class="language-bash"># for javascript
npm install @spider-cloud/spider-client
</code></pre>
<h2 id="usage"><a class="header" href="#usage">Usage</a></h2>
<p>Here is an example of how you can use the library, make sure to replace <code>your_api_key</code> with your actual API key which you can get from the <a href="https://spider.cloud">spider.cloud</a> website.</p>
<pre><code class="language-python">from spider import Spider

app = Spider(api_key='your_api_key')
url = 'https://spider.cloud'
scraped_data = app.scrape_url(url)
</code></pre>
<pre><code class="language-javascript">import { Spider } from "@spider-cloud/spider-client";

const app = new Spider({ apiKey: "your-api-key" });
const url = "https://spider.cloud";
const scrapedData = await app.scrapeUrl(url);
console.log(scrapedData);
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="getting-started"><a class="header" href="#getting-started">Getting started</a></h1>
<p>To use the python SDK you will (of course) have to install it :)</p>
<pre><code class="language-bash">pip install spider-client
</code></pre>
<p><a href="https://pypi.org/project/spider-client/">Here</a> is the link to the package on PyPi.</p>
<h2 id="setting--getting-api-key"><a class="header" href="#setting--getting-api-key">Setting &amp; Getting Api Key</a></h2>
<p>To use the SDK you will need an API key. You can get one by signing up on <a href="https://spider.cloud?ref=python-sdk-book">spider.cloud</a>.</p>
<p>Then you need to set the API key in your environment variables.</p>
<pre><code class="language-bash">export SPIDER_API_KEY=your_api_key
</code></pre>
<p>if you don’t want to set the API key in your environment variables you can pass it as an argument to the <code>Spider</code> class.</p>
<pre><code class="language-python">from spider import Spider
app = Spider(api_key='your_api_key')
</code></pre>
<p>We recommend setting the API key in your environment variables.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="crawl"><a class="header" href="#crawl">Crawl</a></h1>
<p>We will assume that you have installed the Spider package and exported your API key as an environment variable. If you haven’t, please refer to the <a href="#getting-started">Getting Started</a> guide.</p>
<p>Crawl a website and return the content.</p>
<pre><code class="language-python">from spider import Spider

app = Spider()
url = "https://spider.cloud"
crawled_data = app.crawl_url(url, params={"limit": 10})
print(crawled_data)
</code></pre>
<p>The <code>crawl_url</code> method returns the content of the website in markdown format as default. We set the <code>limit</code> parameter to 10 to limit the number of pages to crawl. The maximum amount of pages allowed to crawl per website. Remove the value or set it to <code>0</code> to crawl all pages.</p>
<p>Next we will see how to crawl with with different parameters.</p>
<h2 id="crawl-with-different-parameters"><a class="header" href="#crawl-with-different-parameters">Crawl with different parameters</a></h2>
<p>The <code>crawl_url</code> method has the following parameters:</p>
<ul>
<li><code>url</code> (str): The URL of the website to crawl.</li>
</ul>
<p>the following are recommended parameters and can be set in the <code>params</code> dictionary:</p>
<ul>
<li><code>limit</code> (int): The maximum amount of pages allowed to crawl per website. Remove the value or set it to <code>0</code> to crawl all pages.</li>
<li><code>request_timeout</code> (int): The maximum amount of time to wait for a response from the website.</li>
<li><code>stealth</code> (bool): Whether to use stealth mode. Default is <code>False</code> on chrome.</li>
<li>visit the <a href="https://spider.cloud/docs/api?ref=python-sdk-book">documentation</a> for more parameters.</li>
</ul>
<pre><code class="language-python">from spider import Spider

app = Spider()
url = "https://spider.cloud"
crawled_data = app.crawl_url(
    url, params={"limit": 10, "request_timeout": 10, "stealth": True}
)

print(crawled_data)
</code></pre>
<p>If you have a lot of params, setting them inside the <code>crawl_url</code> method can be cumbersome. You can set them in a seperate <code>params</code> variable that has the <code>RequestParams</code> type which is also available in the <code>spider</code> package.</p>
<pre><code class="language-python">from spider import Spider, spider_types

params: spider_types.RequestParamsDict = {
    "limit": 10,
    "request_timeout": 10,
    "stealth": True,
    "return_format": [ "raw", "markdown" ],
}

app = Spider()
url = "https://spider.cloud"
crawled_data = app.crawl_url(url, params)

print(crawled_data)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="scrape"><a class="header" href="#scrape">Scrape</a></h1>
<p>We will assume that you have installed the Spider package and exported your API key as an environment variable. If you haven’t, please refer to the <a href="#getting-started">Getting Started</a> guide.</p>
<p>Scrape a website and return the content.</p>
<pre><code class="language-python">from spider import Spider

app = Spider()
url = 'https://spider.cloud'
scraped_data = app.scrape_url(url)

print(scraped_data)
</code></pre>
<p>The <code>scrape_url</code> method returns the content of the website in markdown format as default. Next we will see how to scrape with with different parameters.</p>
<h2 id="scrape-with-different-parameters"><a class="header" href="#scrape-with-different-parameters">Scrape with different parameters</a></h2>
<p>The <code>scrape_url</code> method has the following parameters:</p>
<ul>
<li><code>url</code> (str): The URL of the website to scrape.</li>
</ul>
<p>the following are optional parameters and can be set in the <code>params</code> dictionary:</p>
<ul>
<li><code>request</code> (“http”, “chrome”, “smart”) : The type of request to make. Default is “http”.</li>
<li><code>return_format</code> (“raw”, “markdown”, “commonmark”, “html2text”, “text”, “bytes”) : The format in which to return the scraped data. Default is “markdown”.</li>
<li>Other parameters that you can find in the <a href="https://spider.cloud/docs/api?ref=python-sdk-book">documentation</a>.</li>
</ul>
<pre><code class="language-python">from spider import Spider

app = Spider()
url = "https://spider.cloud"
scraped_data = app.scrape_url(url, params={"request_timeout": 10, "stealth": True})

print(scraped_data)
</code></pre>
<p>If you have a lot of params, setting them inside the <code>scrape_url</code> method can be cumbersome. You can set them in a seperate <code>params</code> variable that has the <code>RequestParams</code> type which is also available in the <code>spider</code> package.</p>
<pre><code class="language-python">from spider import Spider, spider_types

params: spider_types.RequestParamsDict = {
    "request_timeout": 10,
    # Easier to read and intellisense will help you with the available options
}

app = Spider()
url = "https://spider.cloud"
scraped_data = app.scrape_url(url, params)

print(scraped_data)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="async-crawl"><a class="header" href="#async-crawl">Async Crawl</a></h1>
<p>We will assume that you have installed the Spider package and exported your API key as an environment variable. If you haven’t, please refer to the <a href="#getting-started">Getting Started</a> guide.</p>
<p>Crawl a website asynchronously and return the content.</p>
<pre><code class="language-python">import asyncio

from spider import AsyncSpider

url = "https://spider.cloud"


async def async_crawl_url(url, params):
    async with AsyncSpider() as app:
        crawled_data = []
        async for data in app.crawl_url(url, params=params):
            crawled_data.append(data)
    return crawled_data


result = asyncio.run(async_crawl_url(url, params={"limit": 10}))
print(result)
</code></pre>
<p>We use the <code>AsyncSpider</code> class to create an asynchronous instance of the Spider class. We then use the <code>async for</code> loop to iterate over the results of the <code>crawl_url</code> method. The <code>crawl_url</code> method returns a generator that yields the crawled data. We append the data to a list and return it. Simsalabim, we have crawled a website asynchronously.</p>
<p>Next we will see how to crawl asynchronously with different parameters.</p>
<h2 id="async-crawl-with-different-parameters"><a class="header" href="#async-crawl-with-different-parameters">Async Crawl with different parameters</a></h2>
<p>The <code>crawl_url</code> method has the following parameters:</p>
<ul>
<li><code>url</code> (str): The URL of the website to crawl.</li>
</ul>
<p>the following are recommended parameters and can be set in the <code>params</code> dictionary:</p>
<ul>
<li><code>limit</code> (int): The maximum amount of pages allowed to crawl per website. Remove the value or set it to <code>0</code> to crawl all pages.</li>
<li><code>request_timeout</code> (int): The maximum amount of time to wait for a response from the website.</li>
<li><code>stealth</code> (bool): Whether to use stealth mode. Default is <code>False</code> on chrome.</li>
<li>a ton more, visit the <a href="https://spider.cloud/docs/api?ref=python-sdk-book">documentation</a> for more parameters.</li>
</ul>
<pre><code class="language-python">import asyncio

from spider import AsyncSpider

url = "https://spider.cloud"


async def async_crawl_url(url, params):
    async with AsyncSpider() as app:
        crawled_data = []
        async for data in app.crawl_url(url, params=params):
            crawled_data.append(data)
    return crawled_data


result = asyncio.run(
    async_crawl_url(
        url,
        params={
            "limit": 10,
            "request_timeout": 10,
            "stealth": True,
            "return_format": "html",
        },
    )
)
print(result)
</code></pre>
<p>If you have a lot of params, setting them inside the <code>crawl_url</code> method can be cumbersome. You can set them in a seperate <code>params</code> variable that has the <code>RequestParams</code> type which is also available in the <code>spider</code> package.</p>
<pre><code class="language-python">import asyncio

from spider import AsyncSpider, spider_types

url = "https://spider.cloud"


async def async_crawl_url(url, params):
    async with AsyncSpider() as app:
        crawled_data = []
        async for data in app.crawl_url(url, params=params):
            crawled_data.append(data)
    return crawled_data


params: spider_types.RequestParamsDict = {
    "limit": 10,
    "request_timeout": 10,
    "stealth": True,
}

result = asyncio.run(async_crawl_url(url, params=params))
print(result)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="getting-started-1"><a class="header" href="#getting-started-1">Getting started</a></h1>
<p>To be able to use the javascript SDK you will (of course) have to install it. You can do so with your package manager of choice.</p>
<pre><code class="language-bash">npm install @spider-cloud/spider-client
</code></pre>
<pre><code class="language-bash">yarn add @spider-cloud/spider-client
</code></pre>
<p><a href="https://www.npmjs.com/package/@spider-cloud/spider-client">Here</a> is the link to the package on npm.</p>
<h2 id="setting--getting-api-key-1"><a class="header" href="#setting--getting-api-key-1">Setting &amp; Getting Api Key</a></h2>
<p>To use the SDK you will need an API key. You can get one by signing up on <a href="https://spider.cloud?ref=javascript-sdk-book">spider.cloud</a>.</p>
<p>Then you need to set the API key in your environment variables.</p>
<pre><code class="language-bash">export SPIDER_API_KEY=your_api_key
</code></pre>
<p>if you don’t want to set the API key in your environment variables you can pass it as an argument to the <code>Spider</code> class.</p>
<pre><code class="language-javascript">import { Spider } from "@spider-cloud/spider-client";
</code></pre>
<p>We recommend setting the API key in your environment variables.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="crawl-1"><a class="header" href="#crawl-1">Crawl</a></h1>
<p>We will assume that you have installed the Spider package and exported your API key as an environment variable. If you haven’t, please refer to the <a href="#getting-started-1">Getting Started</a> guide.</p>
<p>Crawl a website and return the content.</p>
<pre><code class="language-javascript">import { Spider } from "@spider-cloud/spider-client";

const app = new Spider();
const url = "https://spider.cloud";
const scrapedData = await app.crawlUrl(url, { limit: 10 });
console.log(scrapedData);
</code></pre>
<p>The <code>crawlUrl</code> method returns the content of the website in markdown format as default. We set the <code>limit</code> parameter to 10 to limit the number of pages to crawl. The maximum amount of pages allowed to crawl per website. Remove the value or set it to <code>0</code> to crawl all pages.</p>
<p>Next we will see how to crawl with with different parameters.</p>
<h2 id="crawl-with-different-parameters-1"><a class="header" href="#crawl-with-different-parameters-1">Crawl with different parameters</a></h2>
<p>The <code>crawlUrl</code> method has the following parameters:</p>
<ul>
<li><code>url</code> (str): The URL of the website to crawl.</li>
</ul>
<p>the following are recommended parameters and can be set in the <code>params</code> dictionary:</p>
<ul>
<li><code>limit</code> (int): The maximum amount of pages allowed to crawl per website. Remove the value or set it to <code>0</code> to crawl all pages.</li>
<li><code>request_timeout</code> (int): The maximum amount of time to wait for a response from the website.</li>
<li><code>stealth</code> (bool): Whether to use stealth mode. Default is <code>False</code> on chrome.</li>
<li>visit the <a href="https://spider.cloud/docs/api?ref=javascript-sdk-book">documentation</a> for more parameters.</li>
</ul>
<pre><code class="language-javascript">import { Spider } from "@spider-cloud/spider-client";

const app = new Spider();
const url = "https://spider.cloud";
const scrapedData = await app.crawlUrl(url, {
  limit: 10,
  return_format: "raw",
});
console.log(scrapedData);
</code></pre>
<p>If you have a lot of params, setting them inside the <code>crawlUrl</code> method can be cumbersome. You can set them in a seperate <code>params</code> variable that has the <code>SpiderParams</code> type which is also available in the <code>spider</code> package. You will have to use Typescript if you want type annotations.</p>
<pre><code class="language-ts">import { Spider } from "@spider-cloud/spider-client";
import type { SpiderParams } from "@spider-cloud/spider-client/dist/config";

const app = new Spider();
const url = "https://spider.cloud";
const params: SpiderParams = {
  return_format: ["raw", "markdown"],
};
const scrapedData = await app.crawlUrl(url, params);
console.log(scrapedData);
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="scrape-1"><a class="header" href="#scrape-1">Scrape</a></h1>
<p>We will assume that you have installed the Spider package and exported your API key as an environment variable. If you haven’t, please refer to the <a href="#getting-started-1">Getting Started</a> guide.</p>
<p>Scrape a website and return the content.</p>
<pre><code class="language-javascript">import { Spider } from "@spider-cloud/spider-client";

const app = new Spider();
const url = "https://spider.cloud";
const scrapedData = await app.scrapeUrl(url);
console.log(scrapedData);
</code></pre>
<p>The <code>scrapeUrl</code> method returns the content of the website in markdown format as default. Next we will see how to scrape with with different parameters.</p>
<h2 id="scrape-with-different-parameters-1"><a class="header" href="#scrape-with-different-parameters-1">Scrape with different parameters</a></h2>
<p>The <code>scrapeUrl</code> method has the following parameters:</p>
<ul>
<li><code>url</code> (str): The URL of the website to scrape.</li>
</ul>
<p>the following are optional parameters and can be set in the <code>params</code> dictionary:</p>
<ul>
<li><code>request</code> (“http”, “chrome”, “smart”) : The type of request to make. Default is “http”.</li>
<li><code>return_format</code> (“raw”, “markdown”, “commonmark”, “html2text”, “text”, “bytes”) : The format in which to return the scraped data. Default is “markdown”.</li>
<li>Other parameters that you can find in the <a href="https://spider.cloud/docs/api?ref=javascript-sdk-book">documentation</a>.</li>
</ul>
<pre><code class="language-javascript">import { Spider } from "@spider-cloud/spider-client";

const app = new Spider();
const url = "https://spider.cloud";
const scrapedData = await app.scrapeUrl(url, {
  return_format: "raw",
});
console.log(scrapedData);
</code></pre>
<p>If you have a lot of params, setting them inside the <code>scrapeUrl</code> method can be cumbersome. You can set them in a seperate <code>params</code> variable that has the <code>SpiderParams</code> type which is also available in the <code>spider</code> package. You will have to use Typescript if you want type annotations.</p>
<pre><code class="language-ts">import { Spider } from "@spider-cloud/spider-client";
import type { SpiderParams } from "@spider-cloud/spider-client/dist/config";

const app = new Spider();
const url = "https://spider.cloud";
const params: SpiderParams = {
  return_format: "raw"
};
const scrapedData = await app.scrapeUrl(url, params);
console.log(scrapedData);
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="getting-started-2"><a class="header" href="#getting-started-2">Getting Started</a></h1>
<p>The Spider Cloud Rust SDK offers a toolkit for straightforward website scraping, crawling at scale, and other utilities like extracting links and taking screenshots, enabling you to collect data formatted for compatibility with language models (LLMs). It features a user-friendly interface for seamless integration with the Spider Cloud API.</p>
<h2 id="installation-1"><a class="header" href="#installation-1">Installation</a></h2>
<p>To use the Spider Cloud Rust SDK, include the following in your <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[dependencies]
spider-client = "0.1"
</code></pre>
<h2 id="usage-1"><a class="header" href="#usage-1">Usage</a></h2>
<ol>
<li>Get an API key from <a href="https://spider.cloud">spider.cloud</a></li>
<li>Set the API key as an environment variable named <code>SPIDER_API_KEY</code> or pass it as an argument when creating an instance of the <code>Spider</code> struct.</li>
</ol>
<p>Here’s an example of how to use the SDK:</p>
<pre class="playground"><code class="language-rust">use serde_json::json;
use std::env;

#[tokio::main]
async fn main() {
    // Set the API key as an environment variable
    env::set_var("SPIDER_API_KEY", "your_api_key");

    // Initialize the Spider with your API key
    let spider = Spider::new(None).expect("API key must be provided");

    let url = "https://spider.cloud";

    // Scrape a single URL
    let scraped_data = spider.scrape_url(url, None, false, "application/json").await.expect("Failed to scrape the URL");

    println!("Scraped Data: {:?}", scraped_data);

    // Crawl a website
    let crawler_params = RequestParams {
        limit: Some(1),
        proxy_enabled: Some(true),
        metadata: Some(false),
        request: Some(RequestType::Http),
        ..Default::default()
    };

    let crawl_result = spider.crawl_url(url, Some(crawler_params), false, "application/json", None::&lt;fn(serde_json::Value)&gt;).await.expect("Failed to crawl the URL");

    println!("Crawl Result: {:?}", crawl_result);
}</code></pre>
<h3 id="scraping-a-url"><a class="header" href="#scraping-a-url">Scraping a URL</a></h3>
<p>To scrape data from a single URL:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let url = "https://example.com";
let scraped_data = spider.scrape_url(url, None, false, "application/json").await.expect("Failed to scrape the URL");
<span class="boring">}</span></code></pre>
<h3 id="crawling-a-website"><a class="header" href="#crawling-a-website">Crawling a Website</a></h3>
<p>To automate crawling a website:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let url = "https://example.com";
let crawl_params = RequestParams {
    limit: Some(200),
    request: Some(RequestType::Smart),
    ..Default::default()
};
let crawl_result = spider.crawl_url(url, Some(crawl_params), false, "application/json", None::&lt;fn(serde_json::Value)&gt;).await.expect("Failed to crawl the URL");
<span class="boring">}</span></code></pre>
<h4 id="crawl-streaming"><a class="header" href="#crawl-streaming">Crawl Streaming</a></h4>
<p>Stream crawl the website in chunks to scale with a callback:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn handle_json(json_obj: serde_json::Value) {
    println!("Received chunk: {:?}", json_obj);
}

let url = "https://example.com";
let crawl_params = RequestParams {
    limit: Some(200),
    ..Default::default()
};

spider.crawl_url(
    url,
    Some(crawl_params),
    true,
    "application/json",
    Some(handle_json)
).await.expect("Failed to crawl the URL");
<span class="boring">}</span></code></pre>
<h3 id="search"><a class="header" href="#search">Search</a></h3>
<p>Perform a search for websites to crawl or gather search results:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let query = "a sports website";
let crawl_params = RequestParams {
    request: Some(RequestType::Smart),
    search_limit: Some(5),
    limit: Some(5),
    fetch_page_content: Some(true),
    ..Default::default()
};
let crawl_result = spider.search(query, Some(crawl_params), false, "application/json").await.expect("Failed to perform search");
<span class="boring">}</span></code></pre>
<h3 id="retrieving-links-from-a-urls"><a class="header" href="#retrieving-links-from-a-urls">Retrieving Links from a URL(s)</a></h3>
<p>Extract all links from a specified URL:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let url = "https://example.com";
let links = spider.links(url, None, false, "application/json").await.expect("Failed to retrieve links from URL");
<span class="boring">}</span></code></pre>
<h3 id="transform"><a class="header" href="#transform">Transform</a></h3>
<p>Transform HTML to markdown or text lightning fast:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let data = vec![json!({"html": "&lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello world&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;"})];
let params = RequestParams {
    readability: Some(false),
    return_format: Some(ReturnFormat::Markdown),
    ..Default::default()
};
let result = spider.transform(data, Some(params), false, "application/json").await.expect("Failed to transform HTML to markdown");
println!("Transformed Data: {:?}", result);
<span class="boring">}</span></code></pre>
<h3 id="taking-screenshots-of-a-urls"><a class="header" href="#taking-screenshots-of-a-urls">Taking Screenshots of a URL(s)</a></h3>
<p>Capture a screenshot of a given URL:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let url = "https://example.com";
let screenshot = spider.screenshot(url, None, false, "application/json").await.expect("Failed to take screenshot of URL");
<span class="boring">}</span></code></pre>
<h3 id="checking-available-credits"><a class="header" href="#checking-available-credits">Checking Available Credits</a></h3>
<p>You can check the remaining credits on your account:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let credits = spider.get_credits().await.expect("Failed to get credits");
println!("Remaining Credits: {:?}", credits);
<span class="boring">}</span></code></pre>
<h2 id="streaming"><a class="header" href="#streaming">Streaming</a></h2>
<p>If you need to use streaming, set the <code>stream</code> parameter to <code>true</code> and provide a callback function:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn handle_json(json_obj: serde_json::Value) {
    println!("Received chunk: {:?}", json_obj);
}

let url = "https://example.com";
let crawler_params = RequestParams {
    limit: Some(1),
    proxy_enabled: Some(true),
    metadata: Some(false),
    request: Some(RequestType::Http),
    ..Default::default()
};

spider.links(url, Some(crawler_params), true, "application/json").await.expect("Failed to retrieve links from URL");
<span class="boring">}</span></code></pre>
<h2 id="content-type"><a class="header" href="#content-type">Content-Type</a></h2>
<p>The following Content-type headers are supported using the <code>content_type</code> parameter:</p>
<ul>
<li><code>application/json</code></li>
<li><code>text/csv</code></li>
<li><code>application/xml</code></li>
<li><code>application/jsonl</code></li>
</ul>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let url = "https://example.com";

let crawler_params = RequestParams {
    limit: Some(1),
    proxy_enabled: Some(true),
    metadata: Some(false),
    request: Some(RequestType::Http),
    ..Default::default()
};

// Stream JSON lines back to the client
spider.crawl_url(url, Some(crawler_params), true, "application/jsonl", None::&lt;fn(serde_json::Value)&gt;).await.expect("Failed to crawl the URL");
<span class="boring">}</span></code></pre>
<h2 id="error-handling"><a class="header" href="#error-handling">Error Handling</a></h2>
<p>The SDK handles errors returned by the Spider Cloud API and raises appropriate exceptions. If an error occurs during a request, it will be propagated to the caller with a descriptive error message. By default request use a Exponential Backoff to retry as needed.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="getting-started-3"><a class="header" href="#getting-started-3">Getting Started</a></h1>
<p>Spider Cloud CLI is a command-line interface to interact with the <a href="https://spider.cloud">Spider Cloud</a> web crawler. It allows you to scrape, crawl, search, and perform various other web-related tasks through simple commands.</p>
<h2 id="installation-2"><a class="header" href="#installation-2">Installation</a></h2>
<p>Install the CLI using <a href="https://brew.sh/"><code>homebrew</code></a> or <a href="https://doc.rust-lang.org/cargo/"><code>cargo</code></a> from <a href="https://crates.io">crates.io</a>:</p>
<h3 id="homebrew"><a class="header" href="#homebrew">Homebrew</a></h3>
<pre><code class="language-sh">brew tap spider-rs/spider-cloud-cli
brew install spider-cloud-cli
</code></pre>
<h3 id="cargo"><a class="header" href="#cargo">Cargo</a></h3>
<pre><code class="language-sh">cargo install spider-cloud-cli
</code></pre>
<h2 id="usage-2"><a class="header" href="#usage-2">Usage</a></h2>
<p>After installing, you can use the CLI by typing <code>spider-cloud-cli</code> followed by a command and its respective arguments.</p>
<h3 id="authentication"><a class="header" href="#authentication">Authentication</a></h3>
<p>Before using most of the commands, you need to authenticate by providing an API key:</p>
<pre><code class="language-sh">spider-cloud-cli auth --api_key YOUR_API_KEY
</code></pre>
<h3 id="commands"><a class="header" href="#commands">Commands</a></h3>
<h4 id="scrape-2"><a class="header" href="#scrape-2">Scrape</a></h4>
<p>Scrape data from a specified URL.</p>
<pre><code class="language-sh">spider-cloud-cli scrape --url http://example.com
</code></pre>
<h4 id="crawl-2"><a class="header" href="#crawl-2">Crawl</a></h4>
<p>Crawl a specified URL with an optional limit on the number of pages.</p>
<pre><code class="language-sh">spider-cloud-cli crawl --url http://example.com --limit 10
</code></pre>
<h4 id="links"><a class="header" href="#links">Links</a></h4>
<p>Fetch links from a specified URL.</p>
<pre><code class="language-sh">spider-cloud-cli links --url http://example.com
</code></pre>
<h4 id="screenshot"><a class="header" href="#screenshot">Screenshot</a></h4>
<p>Take a screenshot of a specified URL.</p>
<pre><code class="language-sh">spider-cloud-cli screenshot --url http://example.com
</code></pre>
<h4 id="search-1"><a class="header" href="#search-1">Search</a></h4>
<p>Search for a query.</p>
<pre><code class="language-sh">spider-cloud-cli search --query "example query"
</code></pre>
<h4 id="transform-1"><a class="header" href="#transform-1">Transform</a></h4>
<p>Transform specified data.</p>
<pre><code class="language-sh">spider-cloud-cli transform --data "sample data"
</code></pre>
<h4 id="get-credits"><a class="header" href="#get-credits">Get Credits</a></h4>
<p>Fetch the account credits left.</p>
<pre><code class="language-sh">spider-cloud-cli get_credits
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr-ef4e11c1.min.js"></script>
        <script src="mark-09e88c2c.min.js"></script>
        <script src="searcher-c2a407aa.js"></script>

        <script src="clipboard-1626706a.min.js"></script>
        <script src="highlight-abc7f01d.js"></script>
        <script src="book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
